import{_ as a,c as t,a2 as i,o as l}from"./chunks/framework.BQmytedh.js";const o="/assets/image-20231204150839804.d2FUR-B8.png",s="/assets/image-20231204152102440.B9vWVymE.png",R=JSON.parse('{"title":"爬虫基础知识 --笔记","description":"","frontmatter":{},"headers":[],"relativePath":"python/python爬虫/爬虫基础知识.md","filePath":"python/python爬虫/爬虫基础知识.md","lastUpdated":1760021945000}'),r={name:"python/python爬虫/爬虫基础知识.md"};function n(p,e,d,h,u,c){return l(),t("div",null,e[0]||(e[0]=[i(`<h1 id="爬虫基础知识-笔记" tabindex="-1">爬虫基础知识 --笔记 <a class="header-anchor" href="#爬虫基础知识-笔记" aria-label="Permalink to &quot;爬虫基础知识 --笔记&quot;">​</a></h1><blockquote><p>爬虫基础知识</p><p>Scrapy</p><p>BeautifulSoup</p><p>PyQuery</p><p>Selenium</p><p>PySpider</p><p>其他</p></blockquote><h2 id="一、pip" tabindex="-1">一、pip <a class="header-anchor" href="#一、pip" aria-label="Permalink to &quot;一、pip&quot;">​</a></h2><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>作用：只负责安装Python模块</span></span>
<span class="line"><span>镜像源：默认镜像源在国外服务器，当然可以在IDEA中进行设置</span></span></code></pre></div><h2 id="二、url-和-uri" tabindex="-1">二、URL 和 URI <a class="header-anchor" href="#二、url-和-uri" aria-label="Permalink to &quot;二、URL 和 URI&quot;">​</a></h2><p>URL（Universal Resource Locator）：统一资源定位符</p><p>URI（Universal Resource Identifier）：统一资源定位符</p><p>URN（Universal Resource Name）：统一资源名称</p><p>URI = URL + URN</p><p>💡 一般网页可以称为URL 或者 URI</p><h2 id="三、http和https" tabindex="-1">三、Http和Https <a class="header-anchor" href="#三、http和https" aria-label="Permalink to &quot;三、Http和Https&quot;">​</a></h2><p>Http（Hyper Text Transfer Protocol，超文本传输协议）：用于从网络传输超文本数据到本地浏览器的传输协议，它能保证高效而准确地传送超文本文档。</p><p>Https（Hyper Text Transfer Protocol over Secure Socket Layer，超文本传输安全协议）：以安全为目标的HTTP通道，是HTTP的安全版，<code>它在普通的HTTP下加入TLS</code>（Transport Layer Security，传输层安全协议）。TLS是为网络通信提供安全及数据完整性的一种安全协议。</p><p>Https &amp; TLS &amp; SSL 三者的关系</p><ul><li>SSL 在互联网上进行安全传输的协议，用于确保在客户端和服务器之间的数据传输安全<code>已过时</code></li><li>TLS 是 SSL 的后续版本，用于提供安全的通信连接。</li><li>Https 在 HTTP 协议上添加了加密层的安全版本。它使用 TLS 或 SSL 协议来加密 HTTP 通信过程中的数据，确保用户在浏览网站时传输的信息不被第三方窃取或篡改。比如登录信息 和 支付信息</li></ul><p>💡 SSL 是 TLS 的前身，而 TLS 是 SSL 的更加安全和完善的版本。HTTPS 则是在 HTTP 协议上应用了 TLS 或 SSL 协议来实现安全传输，保护网络通信中的数据安全。</p><h2 id="四、http请求过程" tabindex="-1">四、http请求过程 <a class="header-anchor" href="#四、http请求过程" aria-label="Permalink to &quot;四、http请求过程&quot;">​</a></h2><h4 id="_4-1-输入网址" tabindex="-1">4.1 输入网址 <a class="header-anchor" href="#_4-1-输入网址" aria-label="Permalink to &quot;4.1 输入网址&quot;">​</a></h4><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>https://www.baidu.com/</span></span></code></pre></div><h4 id="_4-2-开发者工具" tabindex="-1">4.2 开发者工具 <a class="header-anchor" href="#_4-2-开发者工具" aria-label="Permalink to &quot;4.2 开发者工具&quot;">​</a></h4><p>F12，切换到<code>Network</code>选项，勾选<code>Disable cache</code>，如需显示更多请求信息，可以右键Name列勾选其他需要信息</p><p><img src="`+o+'" alt="image-20231204150839804"></p><h4 id="_4-3-参数解读" tabindex="-1">4.3 参数解读 <a class="header-anchor" href="#_4-3-参数解读" aria-label="Permalink to &quot;4.3 参数解读&quot;">​</a></h4><ul><li>Name，即Request的名称。一般会用URL的最后一部分内容当作名称。</li><li>Method，说明请求的方法，通常有GET，POST等方式，图2-2中显示均为GET方式。</li><li>Status，即Response的状态码。这里显示为200，代表Response是正常的，通过状态码可以判断发送了Request之后是否得到了正常的Response。</li><li>Protocol，即为在网络中进行数据交换而建立的规则、标准或约定。用于不同系统中实体间的通信。 <ul><li><strong>HTTP/1.1</strong>： <ul><li>HTTP/1.1 是第一个被广泛接受和使用的 HTTP 协议的主要版本之一。它是 HTTP/1.0 的升级版本，引入了一些改进，包括持久连接、管道化请求、缓存控制等功能。</li><li>在 HTTP/1.1 中，每个请求和响应都会创建一个新的连接，每个连接只能处理一个请求，并在请求完成后关闭连接。这种方式会导致一些性能上的瓶颈，特别是对于大量小型资源的网页。</li><li>该协议在实际使用中非常常见，几乎所有的网络浏览器和网络服务器都支持 HTTP/1.1。</li></ul></li><li><strong>h2</strong>（HTTP/2）： <ul><li>HTTP/2（简称 h2）是 HTTP 协议的下一代版本，旨在改善性能和效率。</li><li>h2 引入了多路复用、头部压缩、服务器推送等新特性。其中，多路复用允许在同一个连接上并行发送多个请求和响应，避免了 HTTP/1.1 中的连接瓶颈问题。</li><li>头部压缩能够减小传输的头部大小，减少了网络带宽的消耗。服务器推送允许服务器在客户端请求之前主动向客户端发送资源，提高了性能。</li><li>h2 的目标是减少页面加载时间、提高网站性能，尽管它已经推出一段时间，但并没有完全替代 HTTP/1.1。现代浏览器和服务器都支持 HTTP/2，但有些条件下还是会使用 HTTP/1.1，特别是对于一些旧版本的服务器或特殊的网络环境。</li></ul></li></ul></li><li>Type，Request请求的文档类型。第一行为document，代表我们这次请求的是一个HTML文档，内容就是一些HTML代码。另外还有gif，png等其他类型。</li><li>Initiator，请求源。用来标记Request是由哪个对象或进程发起的。其中有Other、<a href="https://www.baidu.xn--com-rz1em08bd99b" target="_blank" rel="noreferrer">https://www.baidu.com等内容</a>。</li><li>Size，从服务器下载的文件和请求的资源大小。如果是从缓存中取得的资源，该列就会显示from memory cache</li><li>Time，发起Request请求到获取Response响应所用的总时间。单位ms为毫秒，0代表从缓存中获取。</li><li>Waterfall，网络请求的可视化瀑布流。</li></ul><h4 id="_4-4-单条请求的详细信息" tabindex="-1">4.4 单条请求的详细信息 <a class="header-anchor" href="#_4-4-单条请求的详细信息" aria-label="Permalink to &quot;4.4 单条请求的详细信息&quot;">​</a></h4><p>单击任意一条请求，可查看详细的请求信息</p><p><img src="'+s+'" alt="image-20231204152102440"></p><ul><li>Request URL为Request请求的URL。</li><li>Request Method为请求的方法。</li><li>Status Code为响应状态码。</li><li>Remote Address为远程服务器的地址和端口。</li><li>Referrer Policy为Referrer判别策略。</li></ul><h2 id="五、请求" tabindex="-1">五、请求 <a class="header-anchor" href="#五、请求" aria-label="Permalink to &quot;五、请求&quot;">​</a></h2><p>Request（请求）由客户端向服务端发出。可以将Request划分为4部分内容：Request Method（请求方式）、Request URL（请求URL地址）、Request Headers（请求头）和Request Body（请求体）。</p><h3 id="_5-1-request-method" tabindex="-1">5.1 Request Method <a class="header-anchor" href="#_5-1-request-method" aria-label="Permalink to &quot;5.1 Request Method&quot;">​</a></h3><p>在浏览器中直接输入一个URL并按回车键，便会发起一个GET请求，请求参数会直接包含到一URL里，如在百度中搜索Python，这就是一个GET请求，链接为：<a href="https://www.baidu.com/s%EF%BC%9F" target="_blank" rel="noreferrer">https://www.baidu.com/s？</a> wd=Python。请求URL中包含请求的参数信息，这里的参数wd就是要搜索的关键词。 POST请求大多为表单提交发起的，如登录表单、输入用户名和密码、单击“登录”按钮，通常会发起一个POST请求，其数据通常以Form Data（表单形式）传输，不会体现在URL中。</p><p>GET和POST请求方法的区别如下： GET请求中的参数包含在URL里面，数据可以在URL中看到，而POST请求的URL不会包含这些数据，数据都是通过表单的形式传输的，会包含在RequestBody中。所以通常情况下，POST请求比GET请求更安全。</p><p><code>GET方式请求提交的数据最多只有1024字节，而POST方式没有限制。</code></p><h3 id="_5-2-request-url" tabindex="-1">5.2 Request URL <a class="header-anchor" href="#_5-2-request-url" aria-label="Permalink to &quot;5.2 Request URL&quot;">​</a></h3><p>唯一确定想请求的资源</p><h3 id="_5-3-request-headers" tabindex="-1">5.3 Request Headers <a class="header-anchor" href="#_5-3-request-headers" aria-label="Permalink to &quot;5.3 Request Headers&quot;">​</a></h3><ul><li>Accept，请求报头域，用于指定客户端可接收哪些类型的信息。</li><li>Accept-Language，指定客户端可接收的语言类型。</li><li>Accept-Encoding，指定客户端可接收的内容编码。</li><li>Host，用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置。</li><li>Cookie/Cookies，是网站为了辨别用户进行Session跟踪而存储在本地的数据。</li><li>Referer，此内容用来标识这个请求是从哪个页面发过来的，服务器可以获取这个信息并进行相应的处理，如来源统计、防盗链处理等。</li><li>User-Agent（UA），这是一个特殊字符串头，使得服务器能够识别客户使用的操作系统及版本、浏览器及版本等信息。在进行爬虫时，加上此信息可以伪装为浏览器，如果不加，就很可能会被识别为爬虫。</li><li>Content-Type，即Internet Media Type，互联网媒体类型，也叫作MIME类型，</li></ul><p>💡 Request Headers是Request的重要组成部分，在编写爬虫程序时大部分情况下都需要设置Request Headers</p><h3 id="_5-4-request-body" tabindex="-1">5.4 Request Body <a class="header-anchor" href="#_5-4-request-body" aria-label="Permalink to &quot;5.4 Request Body&quot;">​</a></h3><p>Post请求中的表单数据，其中Get请求是空</p><p>💡 在Request Headers中指定Content-Type和POST提交数据方式的关系，<code>在爬虫中，如果要构造POST请求，就要注意这几种Content-Type，了解请求库的各个参数设置时使用的是哪种Content-Type，不然可能会导致POST提交后得不到正常的Response</code>。</p><h2 id="六、响应" tabindex="-1">六、响应 <a class="header-anchor" href="#六、响应" aria-label="Permalink to &quot;六、响应&quot;">​</a></h2><p>Response可以划分为3部分：Response Status Code（响应状态码）、Response Headers（响应头）和Response Body（响应体）。</p><ul><li>Response Status Code，表示了服务器的响应状态，如200表示服务器正常响应，404代表页面未找到，500代表服务器内部发生错误。在爬虫中可以根据状态码来判断服务器的响应状态，如判断为200，就证明成功返回数据，再进行进一步处理，否则直接忽略。</li><li>Response Headers，包含服务器对请求的应答信息，如Context-Type，Server，Set- Cookie等。一些常见的头信息说明如下： <ul><li>Date：标识Response产生的时间。</li><li>Last-Modified：指定资源的最后修改时间。</li><li>Content-Encoding：指定Response内容的编码。</li><li>Serve：包含服务器的信息、名称、版本号等。</li><li>Context-Type：文档类型，指定返回的数据类型。</li><li>Set-Cookie：设置Cookie，告诉浏览器要将此内容放在Cookies中，下次请求携带Cookies请求。</li><li>Expires：指定Response的过期时间，使用它可以控制代理服务器或浏览器将内容更新到缓存中，再次访问时直接从缓存中加载，可以降低服务器负载，缩短加载时间。</li></ul></li><li>Response Body，非常重要，响应的正文数据都是在响应体中，如请求一个网页，它的响应体是网页的HTML代码，请求一张图片，响应体就是图片的二进制数据。在爬虫执行时，主要解析的内容就是Response Body，通过Response Body可以得到网页的源代码、JSoN数据等，然后从中进行相应内容的提取。</li></ul><h2 id="七、代理" tabindex="-1">七、代理 <a class="header-anchor" href="#七、代理" aria-label="Permalink to &quot;七、代理&quot;">​</a></h2><h3 id="_7-1-代理原理" tabindex="-1">7.1 代理原理 <a class="header-anchor" href="#_7-1-代理原理" aria-label="Permalink to &quot;7.1 代理原理&quot;">​</a></h3><p>实际上指的就是代理服务器（Proxy Server），它的功能是代理网络用户获取网络信息。形象地说，代理服务器就是网络信息的中转站。</p><p>在用户正常请求一个网站时，发送了请求给Web服务器，Web服务器把响应传回给用户。如果设置了代理服务器，实际上就是在本机和服务器之间搭建了一个桥，此时本机不是直接向Web服务器发起请求，而是向代理服务器发起请求，请求会发送给代理服务器，然后由代理服务器再发送给Web服务器，接着由代理服务器把Web服务器返回的响应转发给本机。</p><h3 id="_7-2-代理作用" tabindex="-1">7.2 代理作用 <a class="header-anchor" href="#_7-2-代理作用" aria-label="Permalink to &quot;7.2 代理作用&quot;">​</a></h3><ul><li>代理可以突破自身IP访问限制，访问一些平时不能访问的站点。比如网上常说的<code>翻墙、科学上网</code>之类就是使用了代理技术。例如使用clash</li><li>使用代理可以访问一些单位或团体的内部资源。</li><li>使用代理可以提高访问速度。<code>通常代理服务器都会设置一个较大的硬盘缓冲区，当有外界的信息通过时，同时也会将其保存到缓冲区中，当其他用户再访问相同的信息时，则直接从缓冲区中取出信息传给用户，以提高访问速度</code>。</li><li>使用代理可以隐藏真实IP。上网者可以通过代理服务隐藏自己的IP，进而免受攻击。对于爬虫来说，使用代理就是为了隐藏自身IP，防止自身的IP被封锁。因为通常大数据量的访问会引起对方主机的怀疑，从而有可能造成封锁IP的访问权限。（爬取那些每天有限制请求次数的网站，如tian地图）</li></ul><p>💡 代理 和 反向代理的区别</p><p>代理服务器是位于客户端和原始服务器之间的中介，而反向代理服务器则是位于公共网络和内部服务器之间的中介。代理服务器用于代表客户端向原始服务器发送请求，而反向代理服务器用于隐藏后端服务器并处理来自客户端的请求。两者的主要区别在于工作方向和位置，以及它们提供的功能和用途。</p><p>💡 nginx的反向代理工作机制 ⭐</p><ol><li><strong>接收客户端请求</strong>： 客户端发送请求到 Nginx 反向代理服务器，请求可以是针对静态资源（如图片、文本文件）或动态内容（如应用程序生成的页面）。</li><li><strong>代理转发请求</strong>： Nginx 接收到客户端的请求后，根据配置的规则，将请求转发给内部服务器，即后端服务器或应用程序服务器，如应用服务器（比如 Node.js、Python Django、Ruby on Rails 等）或者数据库服务器。</li><li><strong>处理请求和响应</strong>： 内部服务器收到请求后，根据请求内容执行相应的处理。例如，对于动态内容的请求，应用服务器会生成相应的页面或数据。</li><li><strong>将响应返回给客户端</strong>： 内部服务器生成响应后，将响应发送回 Nginx 反向代理服务器。</li><li><strong>将响应发送给客户端</strong>： Nginx 接收到来自内部服务器的响应后，再将响应返回给发起请求的客户端。</li></ol><p><code>Nginx 反向代理的优势包括：</code></p><ul><li><strong>负载均衡</strong>：Nginx 可以配置为在多个后端服务器之间均衡负载，分发请求以提高性能和可靠性。</li><li><strong>缓存和静态内容服务</strong>：Nginx 可以缓存静态内容，减少对后端服务器的请求，提高响应速度。</li><li><strong>安全性</strong>：Nginx 可以作为防火墙，过滤恶意请求，提供额外的安全性。</li></ul><h2 id="八、可爬取数据类型" tabindex="-1">八、可爬取数据类型 <a class="header-anchor" href="#八、可爬取数据类型" aria-label="Permalink to &quot;八、可爬取数据类型&quot;">​</a></h2><p>只要是能请求并且能获取响应的数据都能够被抓取，具体包括以下几类：</p><ul><li>网页文本，如HTML文档、JSON格式文本、XML格式文本等。</li><li>图片文件，如JPEG，PNG等图片文件，获取的是二进制文件，保存为相应格式的图片即可。</li><li>视频文件，如MP4，WMV等视频文件，同样获取的是二进制文件，保存为相应的视频格式即可。</li><li>其他文件。只要是能请求到的文件都能获取，比如MP3文件、Flash文件以及其他各种类型的文件。</li></ul>',60)]))}const q=a(r,[["render",n]]);export{R as __pageData,q as default};
