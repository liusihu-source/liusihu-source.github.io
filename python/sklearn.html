<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>sklearn --笔记 | 小Tiger个人笔记网站🐅🐅🐅🐅</title>
    <meta name="description" content="A VitePress site">
    <link rel="stylesheet" href="/assets/style.c48775ea.css">
    <link rel="modulepreload" href="/assets/app.08aaf608.js">
    <link rel="modulepreload" href="/assets/python_sklearn.md.561fdc0b.lean.js">
    
    <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance"),a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-ca9ccb7e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-151f2593></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-151f2593> Skip to content </a><!--]--><!----><header class="VPNav" data-v-ca9ccb7e data-v-a71a30f1><div class="VPNavBar has-sidebar" data-v-a71a30f1 data-v-a35e6f52><div class="container" data-v-a35e6f52><div class="VPNavBarTitle has-sidebar" data-v-a35e6f52 data-v-d5925166><a class="title" href="/" data-v-d5925166><!--[--><!--]--><!--[--><img class="VPImage logo" src="/TOM.jpg" data-v-e13a1912><!--]--><!--[-->小Tiger笔记网站<!--]--><!--[--><!--]--></a></div><div class="content" data-v-a35e6f52><!--[--><!--]--><!----><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-a35e6f52 data-v-f83db6ba><span id="main-nav-aria-label" class="visually-hidden" data-v-f83db6ba>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/python/%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->Python<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/GIS/GeoJson%E6%A0%BC%E5%BC%8F%E8%A7%A3%E8%AF%BB.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->GIS<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/GIT/lecture.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->GIT<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E5%89%8D%E7%AB%AF/html/lecture.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->前端<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E5%90%8E%E7%AB%AF/java/lecture.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->后端<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E7%AE%97%E6%B3%95/lecture.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->算法<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E6%95%B0%E6%8D%AE%E5%BA%93/postgre.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->数据库<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E6%9C%8D%E5%8A%A1%E5%99%A8/WEBGIS%E6%9C%8D%E5%8A%A1.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->服务器<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/Docker/Docker.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->Dcoker<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E5%BB%BA%E6%A8%A1/Revit2019/lecture.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->建模<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E8%BD%AF%E4%BB%B6/catalogue.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->软件<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E8%8B%B1%E8%AF%AD/lecture.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->英语<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E6%95%B0%E5%AD%A6/%E5%9C%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E5%9C%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->数学<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E9%9D%A2%E8%AF%95%E9%A2%98/2022/lecture.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->面试题<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/%E4%B8%AA%E4%BA%BA/%E5%B8%B8%E8%AF%86/lecture.html" data-v-f83db6ba data-v-47a2263e data-v-3c355974><!--[-->个人<!--]--><!----></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-a35e6f52 data-v-a3e7452b><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" data-v-a3e7452b data-v-968780f1 data-v-086e8519><span class="check" data-v-086e8519><span class="icon" data-v-086e8519><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-968780f1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-968780f1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><!----><div class="VPFlyout VPNavBarExtra extra" data-v-a35e6f52 data-v-e89b88d7 data-v-6ffb57d3><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-6ffb57d3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-6ffb57d3><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-6ffb57d3><div class="VPMenu" data-v-6ffb57d3 data-v-1c5d0cfc><!----><!--[--><!--[--><!----><div class="group" data-v-e89b88d7><div class="item appearance" data-v-e89b88d7><p class="label" data-v-e89b88d7>Appearance</p><div class="appearance-action" data-v-e89b88d7><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" data-v-e89b88d7 data-v-968780f1 data-v-086e8519><span class="check" data-v-086e8519><span class="icon" data-v-086e8519><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-968780f1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-968780f1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-a35e6f52 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div><!----></header><div class="VPLocalNav" data-v-ca9ccb7e data-v-aac27d5e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-aac27d5e><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-aac27d5e><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-aac27d5e>Menu</span></button><a class="top-link" href="#" data-v-aac27d5e> Return to top </a></div><aside class="VPSidebar" data-v-ca9ccb7e data-v-f332cb62><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-f332cb62><span class="visually-hidden" id="sidebar-aria-label" data-v-f332cb62> Sidebar Navigation </span><!--[--><div class="group" data-v-f332cb62><section class="VPSidebarGroup collapsible" data-v-f332cb62 data-v-2976c796><div class="title" role="button" data-v-2976c796><h2 class="title-text" data-v-2976c796>Python</h2><div class="action" data-v-2976c796><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="icon minus" data-v-2976c796><path d="M19,2H5C3.3,2,2,3.3,2,5v14c0,1.7,1.3,3,3,3h14c1.7,0,3-1.3,3-3V5C22,3.3,20.7,2,19,2zM20,19c0,0.6-0.4,1-1,1H5c-0.6,0-1-0.4-1-1V5c0-0.6,0.4-1,1-1h14c0.6,0,1,0.4,1,1V19z"></path><path d="M16,11H8c-0.6,0-1,0.4-1,1s0.4,1,1,1h8c0.6,0,1-0.4,1-1S16.6,11,16,11z"></path></svg><svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="icon plus" data-v-2976c796><path d="M19,2H5C3.3,2,2,3.3,2,5v14c0,1.7,1.3,3,3,3h14c1.7,0,3-1.3,3-3V5C22,3.3,20.7,2,19,2z M20,19c0,0.6-0.4,1-1,1H5c-0.6,0-1-0.4-1-1V5c0-0.6,0.4-1,1-1h14c0.6,0,1,0.4,1,1V19z"></path><path d="M16,11h-3V8c0-0.6-0.4-1-1-1s-1,0.4-1,1v3H8c-0.6,0-1,0.4-1,1s0.4,1,1,1h3v3c0,0.6,0.4,1,1,1s1-0.4,1-1v-3h3c0.6,0,1-0.4,1-1S16.6,11,16,11z"></path></svg></div></div><div class="items" data-v-2976c796><!--[--><a class="VPLink link link" href="/python/%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95.html" data-v-2976c796 data-v-f7e544fc data-v-3c355974><!--[--><span class="link-text" data-v-f7e544fc>基本用法</span><!----><!--]--><!----></a><a class="VPLink link link" href="/python/%E7%88%AC%E8%99%AB.html" data-v-2976c796 data-v-f7e544fc data-v-3c355974><!--[--><span class="link-text" data-v-f7e544fc>爬虫</span><!----><!--]--><!----></a><a class="VPLink link link" href="/python/%E8%A3%85%E5%8C%85.html" data-v-2976c796 data-v-f7e544fc data-v-3c355974><!--[--><span class="link-text" data-v-f7e544fc>装包</span><!----><!--]--><!----></a><a class="VPLink link link" href="/python/excelTxt.html" data-v-2976c796 data-v-f7e544fc data-v-3c355974><!--[--><span class="link-text" data-v-f7e544fc>Txt&amp;Excel读写</span><!----><!--]--><!----></a><a class="VPLink link link" href="/python/Osgeo.html" data-v-2976c796 data-v-f7e544fc data-v-3c355974><!--[--><span class="link-text" data-v-f7e544fc>Osgeo</span><!----><!--]--><!----></a><a class="VPLink link link" href="/python/GeoPandas.html" data-v-2976c796 data-v-f7e544fc data-v-3c355974><!--[--><span class="link-text" data-v-f7e544fc>Geopandas</span><!----><!--]--><!----></a><a class="VPLink link link active" href="/python/sklearn.html" data-v-2976c796 data-v-f7e544fc data-v-3c355974><!--[--><span class="link-text" data-v-f7e544fc>sklearn</span><!----><!--]--><!----></a><!--]--></div></section></div><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-ca9ccb7e data-v-407bd980><div class="VPDoc has-sidebar has-aside" data-v-407bd980 data-v-f0af2311><div class="container" data-v-f0af2311><div class="aside" data-v-f0af2311><div class="aside-curtain" data-v-f0af2311></div><div class="aside-container" data-v-f0af2311><div class="aside-content" data-v-f0af2311><div class="VPDocAside" data-v-f0af2311 data-v-aea49c31><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline has-outline" data-v-aea49c31 data-v-a3de185c><div class="content" data-v-a3de185c><div class="outline-marker" data-v-a3de185c></div><div class="outline-title" data-v-a3de185c>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-a3de185c><span class="visually-hidden" id="doc-outline-aria-label" data-v-a3de185c> Table of Contents for current page </span><ul class="root" data-v-a3de185c><!--[--><li data-v-a3de185c><a class="outline-link" href="#_1、测试images-py" data-v-a3de185c>1、测试images.py</a><!----></li><li data-v-a3de185c><a class="outline-link" href="#_2、neuralnetwork-py" data-v-a3de185c>2、NeuralNetwork.py</a><!----></li><li data-v-a3de185c><a class="outline-link" href="#_3、digitalreconginize" data-v-a3de185c>3、DigitalReconginize</a><!----></li><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-aea49c31></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-f0af2311><div class="content-container" data-v-f0af2311><!--[--><!--]--><main class="main" data-v-f0af2311><div style="position:relative;" class="vp-doc _python_sklearn" data-v-f0af2311><div><h1 id="sklearn-笔记" tabindex="-1">sklearn --笔记 <a class="header-anchor" href="#sklearn-笔记" aria-hidden="true">#</a></h1><h3 id="_1、测试images-py" tabindex="-1">1、<a href="http://xn--images-hf3nq86q.py" target="_blank" rel="noreferrer">测试images.py</a> <a class="header-anchor" href="#_1、测试images-py" aria-hidden="true">#</a></h3><div class="language-python"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> matplotlib</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">pyplot</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">as</span><span style="color:#A6ACCD;"> plt</span></span>
<span class="line"><span style="color:#89DDFF;">from</span><span style="color:#A6ACCD;"> sklearn</span><span style="color:#89DDFF;">.</span><span style="color:#A6ACCD;">datasets </span><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> load_digits</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">digits </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">load_digits</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">digits</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">data</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">shape</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">plt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">gray</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;">#用于将颜色映射方式设置为灰度图像</span></span>
<span class="line"><span style="color:#A6ACCD;">plt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">matshow</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">digits</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">images</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">])</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;">#mat是matrix缩写，矩阵意思。这里利用plt依赖库将读取到的8*8的矩阵绘制成8*8的灰度图像</span></span>
<span class="line"><span style="color:#A6ACCD;">plt</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">show</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;">#这里是将刚才绘制的灰度图像显示出来</span></span>
<span class="line"></span>
<span class="line"></span></code></pre></div><h3 id="_2、neuralnetwork-py" tabindex="-1">2、<a href="http://NeuralNetwork.py" target="_blank" rel="noreferrer">NeuralNetwork.py</a> <a class="header-anchor" href="#_2、neuralnetwork-py" aria-hidden="true">#</a></h3><div class="language-python"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#676E95;">#引入依赖包</span></span>
<span class="line"><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> numpy </span><span style="color:#89DDFF;">as</span><span style="color:#A6ACCD;"> np</span></span>
<span class="line"><span style="color:#676E95;">#定义激活函数这些基本方法</span></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">tanh</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">x</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">return</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">tanh</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">tanh_deriv</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">x</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">return</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">1.0</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">-</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">tanh</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">*</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">tanh</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">logistic</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">x</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">return</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">1</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">/</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">(</span><span style="color:#F78C6C;">1</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">+</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">exp</span><span style="color:#89DDFF;">(-</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">logistic_deriv</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">x</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">return</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">logistic</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">*</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">(</span><span style="color:#F78C6C;">1</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">-</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">logistic</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">))</span></span>
<span class="line"><span style="color:#676E95;">#创建NeuralNetwork类别</span></span>
<span class="line"><span style="color:#C792EA;">class</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">NeuralNetwork</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;">#初始化</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">__init__</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">self</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;">layers</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;">activation</span><span style="color:#89DDFF;">=</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">tanh</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;">#确定具体激活函数</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">if</span><span style="color:#A6ACCD;"> activation </span><span style="color:#89DDFF;">==</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">logistic</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">            self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">activation</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> logistic</span></span>
<span class="line"><span style="color:#A6ACCD;">            self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">activation_deriv</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> logistic_deriv</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">elif</span><span style="color:#A6ACCD;"> activation </span><span style="color:#89DDFF;">==</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">tanh</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">            self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">activation</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> tanh</span></span>
<span class="line"><span style="color:#A6ACCD;">            self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">activation_deriv</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> tanh_deriv</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;">#创建weights列表，用于存储权重值，即存储相邻神经网络层间的权重连接值，即理解为如课堂上讲的hw11等</span></span>
<span class="line"><span style="color:#A6ACCD;">        self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[]</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;">#这四个print用于个人理解代码时候测试使用</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">len</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">layers</span><span style="color:#89DDFF;">))</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;">#3，也就是三个层，输入、隐藏和输出三层神经</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">layers</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;">#65，表示输入层，64个神经维度 + 1 = 65个维度，即1个有65维度的列向量</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">layers</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;">#101，表示隐藏层，100个神经维度 + 1 = 101维度，即1个有101维度的列向量</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">np</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">random</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">random</span><span style="color:#89DDFF;">((</span><span style="color:#82AAFF;">layers</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> layers</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">)))</span><span style="color:#A6ACCD;">   </span><span style="color:#676E95;">#生成一个65行 101列的浮点型列表，每个浮点数都在0-1之间</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#676E95;">        这里range(1,2)，即只遍历l=1这一次</span></span>
<span class="line"><span style="color:#676E95;">        np.random.random((layers[i - 1] + 1, layers[i] + 1))，返回一个65行 101列的浮点型列表，每个浮点数都在0-1之间，具体的计算见下图</span></span>
<span class="line"><span style="color:#676E95;">        权重weights列表加入该65*101的二维列表</span></span>
<span class="line"><span style="color:#676E95;">        后面的公式类似，weights再加入一个101 * 10 的二维列表，值的范围相同</span></span>
<span class="line"><span style="color:#676E95;">        这两个二维列表可以理解为课堂上讲的输入层与隐藏层间的连接、隐藏层与输出层间的连接</span></span>
<span class="line"><span style="color:#676E95;">        </span><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">for</span><span style="color:#A6ACCD;"> i </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">range</span><span style="color:#89DDFF;">(</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> len</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">layers</span><span style="color:#89DDFF;">)</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">-</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;">#间接理解为建立层之间的连接，层之间的神经元连接权重是范围-0.25 ~ 0.25</span></span>
<span class="line"><span style="color:#A6ACCD;">            self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">append</span><span style="color:#89DDFF;">((</span><span style="color:#F78C6C;">2</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">*</span><span style="color:#82AAFF;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">random</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">random</span><span style="color:#89DDFF;">((</span><span style="color:#82AAFF;">layers</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">i </span><span style="color:#89DDFF;">-</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> layers</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">i</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">))</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">-</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">)</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">*</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">0.25</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;">#生成一个65行 101列的二维矩阵</span></span>
<span class="line"><span style="color:#A6ACCD;">            self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">append</span><span style="color:#89DDFF;">((</span><span style="color:#F78C6C;">2</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">*</span><span style="color:#82AAFF;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">random</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">random</span><span style="color:#89DDFF;">((</span><span style="color:#82AAFF;">layers</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">i</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> layers</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">i </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">]))</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">-</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">)</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">*</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">0.25</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;">#生成一个101行 10列的二维矩阵</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;">#定义fit方法，用于训练神经网络</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">fit</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">self</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;">x</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;">y</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;">learning_rate</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">0.2</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;">epochs</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">10000</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#676E95;">        :param x:对应传过来的1347 * 64，内部值均已经归一化0-1</span></span>
<span class="line"><span style="color:#676E95;">        :param y:对应1347 * 10，已经二值化后的结果</span></span>
<span class="line"><span style="color:#676E95;">        :param learning_rate:学习率</span></span>
<span class="line"><span style="color:#676E95;">        :param epochs:迭代次数，也是终止条件</span></span>
<span class="line"><span style="color:#676E95;">        </span><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;"># atleast_2d，该方法将输入值改为二维数组，至少是二维矩阵</span></span>
<span class="line"><span style="color:#A6ACCD;">        x </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">atleast_2d</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;"># 返回一个具有指定形状和数据类型的新数组，并且数组值均为1，默认数据类型是float64，同时可以设置其他，如int8</span></span>
<span class="line"><span style="color:#A6ACCD;">        temp </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">ones</span><span style="color:#89DDFF;">([</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">shape</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">],</span><span style="color:#82AAFF;"> x</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">shape</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#676E95;">        此时temp是1347 * 65的二维矩阵，每个位置值均为1.0</span></span>
<span class="line"><span style="color:#676E95;">        [:, 0:-1] = x，即所有行，所有行的前64列重新赋值为初始的已经归一化好的1347 * 64的二维列表的值，同时最后一列的1保持不变，即课堂上提到的偏置</span></span>
<span class="line"><span style="color:#676E95;">        y是将1347 * 10的二维列表改为矩阵</span></span>
<span class="line"><span style="color:#676E95;">        最后更新x、y结果，看如下图示</span></span>
<span class="line"><span style="color:#676E95;">        </span><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#A6ACCD;">        temp</span><span style="color:#89DDFF;">[:,</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">:-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">]</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> x</span></span>
<span class="line"><span style="color:#A6ACCD;">        x </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> temp</span></span>
<span class="line"><span style="color:#A6ACCD;">        y </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">array</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">y</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;">#开始迭代训练</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">for</span><span style="color:#A6ACCD;"> k </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">range</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">epochs</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;">#randint是选出参数中的任一随机整数值，从1347*65矩阵的x中，从该0-1347中随机取出一个行数</span></span>
<span class="line"><span style="color:#A6ACCD;">            i </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">random</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">randint</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">shape</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;"># 查看具体随机行数</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">i</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;">#此时a即 1 * 65，用该a首次训练神经网络模型</span></span>
<span class="line"><span style="color:#A6ACCD;">            a </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span><span style="color:#A6ACCD;">x</span><span style="color:#89DDFF;">[</span><span style="color:#A6ACCD;">i</span><span style="color:#89DDFF;">]]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;">#开始正向传递</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">for</span><span style="color:#A6ACCD;"> l </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">range</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">len</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">)):</span></span>
<span class="line"><span style="color:#A6ACCD;">                </span><span style="color:#676E95;"># dot是矩阵乘积的方法，activation是用激活函数对乘积结果进行收敛</span></span>
<span class="line"><span style="color:#A6ACCD;">                </span><span style="color:#676E95;"># 此时先是乘积为 [1行65列] * [65行101列] = [1行101列]，</span></span>
<span class="line"><span style="color:#A6ACCD;">                </span><span style="color:#676E95;"># 因为是range(2)，所以之后再遍历第二次，此时乘积为 [1行101列] * [101行10列] = [1行10列]加一个数组，最后存储一个1*10的列向量矩阵，完成正向的传递</span></span>
<span class="line"><span style="color:#A6ACCD;">                </span><span style="color:#676E95;"># 最后用激活函数logistic对乘积结果进行收敛</span></span>
<span class="line"><span style="color:#A6ACCD;">                </span><span style="color:#676E95;"># print(&quot;a[&quot;+str(l)+&quot;]; &quot;+str(a[l])+&quot;  WEIGHT &quot;+str(self.weights[l])+str(len(self.weights)))</span></span>
<span class="line"><span style="color:#A6ACCD;">                </span><span style="color:#676E95;"># 可用上行注释查看两个矩阵，尝试自行乘积，之后用激活函数收敛。结课报告中提供思路尝试得到乘积结果并进行收敛计算</span></span>
<span class="line"><span style="color:#A6ACCD;">                a</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">append</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">activation</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">dot</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">a</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">l</span><span style="color:#89DDFF;">],</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">[</span><span style="color:#F07178;">l</span><span style="color:#89DDFF;">])))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;"># 是一个1*10的矩阵，其中有一个位置是1，其他均为0</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">y</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">i</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;"># 是一个1*10的矩阵，最后刚才的收敛结果</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">a</span><span style="color:#89DDFF;">[-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;"># 是一个1*10矩阵，即矩阵减法结果，误差率</span></span>
<span class="line"><span style="color:#A6ACCD;">            error </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> y</span><span style="color:#89DDFF;">[</span><span style="color:#A6ACCD;">i</span><span style="color:#89DDFF;">]</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">-</span><span style="color:#A6ACCD;"> a</span><span style="color:#89DDFF;">[-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">error</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;">#反向误差值计算，deltas = 误差率 * 最后一层的神经元值</span></span>
<span class="line"><span style="color:#A6ACCD;">            deltas </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span><span style="color:#A6ACCD;">error </span><span style="color:#89DDFF;">*</span><span style="color:#A6ACCD;"> self</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">activation_deriv</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">a</span><span style="color:#89DDFF;">[-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">])]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#676E95;">#开始反向更新,内部诸多数学公式及数组内的序列计算过多，这里不做过多赘述。最终达到预设一定的循环次数10000后会保存一个神经网络模型.</span></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">for</span><span style="color:#A6ACCD;"> l </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">range</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">len</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">a</span><span style="color:#89DDFF;">)</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">-</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">                deltas</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">append</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">deltas</span><span style="color:#89DDFF;">[-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">].</span><span style="color:#82AAFF;">dot</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">[</span><span style="color:#F07178;">l</span><span style="color:#89DDFF;">].</span><span style="color:#F07178;">T</span><span style="color:#89DDFF;">)</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">*</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">activation_deriv</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">a</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">l</span><span style="color:#89DDFF;">]))</span></span>
<span class="line"><span style="color:#A6ACCD;">            deltas</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">reverse</span><span style="color:#89DDFF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">            </span><span style="color:#89DDFF;">for</span><span style="color:#A6ACCD;"> i </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">range</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">len</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">)):</span></span>
<span class="line"><span style="color:#A6ACCD;">                layer </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">atleast_2d</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">a</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">i</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">                delta </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">atleast_2d</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">deltas</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">i</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">                self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">[</span><span style="color:#F07178;">i</span><span style="color:#89DDFF;">]</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">+=</span><span style="color:#A6ACCD;"> learning_rate </span><span style="color:#89DDFF;">*</span><span style="color:#A6ACCD;"> layer</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">T</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">dot</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">delta</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;">#定义predict方法，用于测试神经网络</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">predict</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">self</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;">x</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;">#这里同上面的fit初始x相同，最终目的得到1*65的矩阵，前边是x，最后加一个偏置1</span></span>
<span class="line"><span style="color:#A6ACCD;">        x </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">array</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">        temp </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">ones</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">shape</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">]</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">+</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">        temp</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">:-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">]</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> x</span></span>
<span class="line"><span style="color:#A6ACCD;">        a </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> temp</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;"># 这里先是[[1*65] * [65*101]] =&gt; [1*101] =&gt; [[1*101] * [101*10]] = &gt; [1 * 10], 最后激活函数收敛，返回a</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#676E95;"># a是 1 * 10，内部10个数字会有值之间的大小关系，最后用argmax取最大值的索引位置值，即表示这个测试集x可能代表的标签值</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">for</span><span style="color:#A6ACCD;"> l </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">range</span><span style="color:#89DDFF;">(</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> len</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">)):</span></span>
<span class="line"><span style="color:#A6ACCD;">            a </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> self</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">activation</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">dot</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">a</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;">self</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">weights</span><span style="color:#89DDFF;">[</span><span style="color:#F07178;">l</span><span style="color:#89DDFF;">]))</span></span>
<span class="line"><span style="color:#A6ACCD;">        </span><span style="color:#89DDFF;">return</span><span style="color:#A6ACCD;"> a</span></span>
<span class="line"></span>
<span class="line"></span></code></pre></div><h3 id="_3、digitalreconginize" tabindex="-1">3、DigitalReconginize <a class="header-anchor" href="#_3、digitalreconginize" aria-hidden="true">#</a></h3><div class="language-python"><button class="copy"></button><span class="lang">python</span><pre><code><span class="line"><span style="color:#676E95;">#引用依赖包</span></span>
<span class="line"><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> joblib</span></span>
<span class="line"><span style="color:#89DDFF;">from</span><span style="color:#A6ACCD;"> sklearn</span><span style="color:#89DDFF;">.</span><span style="color:#A6ACCD;">preprocessing </span><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> LabelBinarizer</span></span>
<span class="line"><span style="color:#89DDFF;">from</span><span style="color:#A6ACCD;"> NeuralNetwork </span><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> NeuralNetwork</span></span>
<span class="line"><span style="color:#89DDFF;">from</span><span style="color:#A6ACCD;"> sklearn</span><span style="color:#89DDFF;">.</span><span style="color:#A6ACCD;">model_selection </span><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> train_test_split</span></span>
<span class="line"><span style="color:#89DDFF;">from</span><span style="color:#A6ACCD;"> sklearn</span><span style="color:#89DDFF;">.</span><span style="color:#A6ACCD;">datasets </span><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> load_digits</span></span>
<span class="line"><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> numpy </span><span style="color:#89DDFF;">as</span><span style="color:#A6ACCD;"> np</span></span>
<span class="line"><span style="color:#89DDFF;">from</span><span style="color:#A6ACCD;"> sklearn</span><span style="color:#89DDFF;">.</span><span style="color:#A6ACCD;">metrics </span><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> confusion_matrix</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> classification_report</span></span>
<span class="line"><span style="color:#89DDFF;">import</span><span style="color:#A6ACCD;"> warnings</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;"># 过滤警告标签，warming 是 python内置库，python中常遇到报错的情况，但不影响程序的运行，对于这些错误可以通过warming来去除这些警告错误</span></span>
<span class="line"><span style="color:#A6ACCD;">warnings</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">filterwarnings</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">ignore</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;"># 加载全部数据集</span></span>
<span class="line"><span style="color:#A6ACCD;">digits </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">load_digits</span><span style="color:#89DDFF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;"># 所有训练集，内部包含1797个样本数据，每个数据是8*8的灰度图像，即64个维度，现在即1797 * 64</span></span>
<span class="line"><span style="color:#A6ACCD;">x </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> digits</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">data</span></span>
<span class="line"><span style="color:#676E95;"># 所有真实值标签，即样本代表的实际真实数字值</span></span>
<span class="line"><span style="color:#A6ACCD;">y </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> digits</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">target</span></span>
<span class="line"><span style="color:#676E95;"># 数据与处理，让特征值都处在0-1之间，即对应课堂上讲的归一化处理，具体的数学公式解释如下图</span></span>
<span class="line"><span style="color:#A6ACCD;">x </span><span style="color:#89DDFF;">-=</span><span style="color:#A6ACCD;"> x</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">min</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#A6ACCD;">x </span><span style="color:#89DDFF;">/=</span><span style="color:#A6ACCD;"> x</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">max</span><span style="color:#89DDFF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;"># 构建神经网络结构</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#676E95;">利用上面引用的依赖包，创建对应该包中提供的NeuralNetwork类</span></span>
<span class="line"><span style="color:#676E95;">该类有两个参数，第一个参数是一个列表，包含了每层神经网络包含多少个神经元</span></span>
<span class="line"><span style="color:#676E95;">64,100,10 》》 输入层有64个神经维度，中间隐藏层有100个神经维度，输出层有10个神经维度，对应最终要识别的0-9这10个数字</span></span>
<span class="line"><span style="color:#676E95;">第二个参数是激活函数，可选项，如果不做设置，默认选择tanh。这里只是设置了logistic，设置激活函数目的是防止神经节点的数值不能过大，避免出现不能最终收敛的情况，也可以加快学习速度【注意logistic不是取对数】。</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#A6ACCD;">nn </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">NeuralNetwork</span><span style="color:#89DDFF;">([</span><span style="color:#F78C6C;">64</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">100</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#F78C6C;">10</span><span style="color:#89DDFF;">],</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">logistic</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#676E95;"># 切分训练集和测试集</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#676E95;">train_test_split是sklearn依赖包的内部方法，该方法可以将原始数据集将训练集和测试集差分，默认拆分比例是3:1，按照1797总数，所以训练集有1347个，测试集有450个</span></span>
<span class="line"><span style="color:#676E95;">x_train是训练集的所有影像维度和，即1347 * 64；x_test是测试集所有影像维度和，即450 * 64；</span></span>
<span class="line"><span style="color:#676E95;">y_train是训练集的所有真实标签和，即1347 * 1；y_test是测试集的所有真实标签和，即450 * 1；</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#A6ACCD;">x_train</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> x_test</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> y_train</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> y_test </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">train_test_split</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> y</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#676E95;"># 对标记进行二值化</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#676E95;">fit_transform是sklearn依赖包的内部方法，该方法可以将某一具体数值进行二值化存储。</span></span>
<span class="line"><span style="color:#676E95;">如数字4可以表示[0 0 0 0 1 0 0 0 0 0]；1可以表示为[0 1 0 0 0 0 0 0 0 0]</span></span>
<span class="line"><span style="color:#676E95;">label_train，原先y_train是1347 * 1， 二值化后是1347 * 10</span></span>
<span class="line"><span style="color:#676E95;">label_test，原先y_test是450 * 1，二值化后是450 * 10</span></span>
<span class="line"><span style="color:#676E95;">这样存储真实标签值的目的是为了后面神经网络训练时候的误差检查及反向传递方便计算</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#A6ACCD;">label_train </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">LabelBinarizer</span><span style="color:#89DDFF;">().</span><span style="color:#82AAFF;">fit_transform</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">y_train</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">label_test </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">LabelBinarizer</span><span style="color:#89DDFF;">().</span><span style="color:#82AAFF;">fit_transform</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">y_test</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#676E95;">#控制台输出start fitting..</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">start fitting..</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#676E95;">fit是NeuralNetwork内的一个方法</span></span>
<span class="line"><span style="color:#676E95;">该方法用于训练神经网络，最终得到一个较好的训练模型</span></span>
<span class="line"><span style="color:#676E95;">x_train是刚才的训练集，1347 * 64(此时已经归一化好了)</span></span>
<span class="line"><span style="color:#676E95;">label_train是刚才的训练集结果，1347 * 10(二值化后的结果)</span></span>
<span class="line"><span style="color:#676E95;">epochs是迭代次数，是停止训练的中断条件，即超过10000次就不训练了，即认为大致精度可以了</span></span>
<span class="line"><span style="color:#676E95;">具体如何训练的，请看NeuralNetwork内的代码详解</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#A6ACCD;">nn</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">fit</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x_train</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> label_train</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;">epochs</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">10000</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;">#保存最后的训练模型，可以利用该模型进行其他测试数据集的测试</span></span>
<span class="line"><span style="color:#676E95;">#joblib.dump(nn, &#39;E:\\课程\\大四上\\机器学习\\nnModel.m&#39;)</span></span>
<span class="line"><span style="color:#676E95;">#创建空数组，用于存储测试样本经过网络训练后得到的最终结果标签</span></span>
<span class="line"><span style="color:#A6ACCD;">predictions </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[]</span></span>
<span class="line"><span style="color:#89DDFF;">for</span><span style="color:#A6ACCD;"> i </span><span style="color:#89DDFF;">in</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">range</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">y_test</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">shape</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">]):</span></span>
<span class="line"><span style="color:#A6ACCD;">    o </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> nn</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">predict</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">x_test</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">i</span><span style="color:#89DDFF;">])</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;">#argmax是降维的方法，本次即取一个行矩阵中最大位置的值的索引值，也就代表了该测试样本的预测标签</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#676E95;">#最后遍历完所有的测试数据集，会为每一个样本生成一个预测的预测标签，并依次添加到predictions中</span></span>
<span class="line"><span style="color:#A6ACCD;">    predictions</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">append</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">np</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">argmax</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">o</span><span style="color:#89DDFF;">))</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#676E95;">用测试数据集的预测标签和该样本的本身真实标签做对比</span></span>
<span class="line"><span style="color:#676E95;">confusion_matrix是sklearn依赖包的内部方法，该方法最终会返回一个情形分析表，并以矩阵的方式存储真实类别和预测类别，具体详解见结果分析</span></span>
<span class="line"><span style="color:#676E95;">classification_report是sklearn依赖包的内部方法，该方法会返回一个分析结果，具体详解见结果分析</span></span>
<span class="line"><span style="color:#89DDFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">confusion_matrix</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">y_test</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> predictions</span><span style="color:#89DDFF;">))</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">classification_report</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">y_test</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> predictions</span><span style="color:#89DDFF;">))</span></span>
<span class="line"></span>
<span class="line"></span></code></pre></div><ul><li><strong>相关截图</strong></li></ul><p><img src="/assets/1666877621703.e4a719b1.png" alt="1666877621703"></p><p><img src="/assets/1666877666094.29fe7a73.png" alt="1666877666094"></p><p><img src="/assets/1666877639606.590d46a6.png" alt="1666877639606"></p><p><img src="/assets/1666877645837.5b541499.png" alt="1666877645837"></p><p>​ <img src="/assets/1666877690217.727f3df5.png" alt="1666877690217"></p><p><img src="/assets/1666877697366.d54bf320.png" alt="1666877697366"></p><p><img src="/assets/1666877702205.28944fa8.png" alt="1666877702205"></p><p><img src="/assets/1666877708229.0ccb8e69.png" alt="1666877708229"></p><p><img src="/assets/1666877712069.f836d411.png" alt="1666877712069"></p><p><img src="/assets/1666877716102.558b780b.png" alt="1666877716102"></p><p><img src="/assets/1666877721364.3d4c9dcd.png" alt="1666877721364"></p></div></div></main><!--[--><!--]--><footer class="VPDocFooter" data-v-f0af2311 data-v-a54a85bd><!----><div class="prev-next" data-v-a54a85bd><div class="pager" data-v-a54a85bd><a class="pager-link prev" href="/python/GeoPandas.html" data-v-a54a85bd><span class="desc" data-v-a54a85bd>Previous page</span><span class="title" data-v-a54a85bd>Geopandas</span></a></div><div class="has-prev pager" data-v-a54a85bd><!----></div></div></footer><!--[--><!--]--></div></div></div></div></div><!----><!--[--><!--]--></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"docker_docker.md\":\"46e70b6b\",\"gis_cesium_3dtiles规范解读.md\":\"0e8fc143\",\"gis_cesium_3dtiling.md\":\"2ff4dd18\",\"gis_cesium_cesiumapi图.md\":\"c5a69c02\",\"gis_cesium_cesiumion.md\":\"d5b6cf93\",\"gis_cesium_cesiumjs.md\":\"0a9a104b\",\"gis_cesium_cesiumlab.md\":\"f7fac550\",\"gis_cesium_createentities.md\":\"bcfd8d1f\",\"gis_cesium_visualize3dterrain.md\":\"e34eb4c7\",\"gis_cesium_visualizeimagery.md\":\"bd402a77\",\"gis_cesium_particlesystem.md\":\"becfa905\",\"gis_cesium_sihucesiummap.md\":\"ea101c01\",\"gis_cesium_专业英语单词.md\":\"296a01ff\",\"gis_cesium_切片.md\":\"8feb0819\",\"gis_cesium_坐标.md\":\"946af29f\",\"gis_gis常用空间分析.md\":\"480fcff3\",\"gis_geojson格式解读.md\":\"205dc08d\",\"gis_opengl_opengl.md\":\"062e05eb\",\"gis_turf_turf.md\":\"b92bae10\",\"gis_常用坐标系及epsg.md\":\"84f4acb3\",\"gis_遥感_基础概论.md\":\"e8117739\",\"gis_遥感_常见卫星和影像.md\":\"49b1203b\",\"git_lecture.md\":\"f3075adb\",\"index.md\":\"12c53eec\",\"python_geopandas.md\":\"168c5aed\",\"python_osgeo.md\":\"2e445573\",\"python_exceltxt.md\":\"3ff57f15\",\"python_sklearn.md\":\"561fdc0b\",\"python_基本用法.md\":\"685c1f5a\",\"python_爬虫.md\":\"3ea48cc2\",\"python_装包.md\":\"cffe34a9\",\"个人_jeecglearn_jeecgvue.md\":\"86cbf34c\",\"个人_个人介绍_基本介绍.md\":\"b2e4d67d\",\"个人_个人介绍_小作品.md\":\"8d4886db\",\"个人_常识_lecture.md\":\"60b9f71c\",\"个人_毕设_本科毕设.md\":\"7842026e\",\"前端_js_lecture.md\":\"5f33b7ff\",\"前端_vitepress_vitepress.md\":\"070c695b\",\"前端_axios_lecture.md\":\"5014f330\",\"前端_html_h5.md\":\"cce0b403\",\"前端_html_lecture.md\":\"0a5d42ab\",\"前端_typescript_笔记.md\":\"fcd2f462\",\"前端_vite_vite.md\":\"9fd473fd\",\"前端_vite_vitesvg.md\":\"d409d68d\",\"前端_vite_多环境构建配置.md\":\"a9aa26fa\",\"前端_vite_项目结构.md\":\"8a5eea83\",\"前端_vue_vue2_生命周期.md\":\"3432f2c3\",\"前端_vue_vue3_vue3setup.md\":\"750c2f0a\",\"前端_vue_vue3_vue3快速上手.md\":\"03616ed9\",\"前端_vue_vue3_生命周期.md\":\"b1bcd3c1\",\"前端_vue_uni-app_lecture.md\":\"75f119da\",\"前端_vue_共用_vuex.md\":\"56c19532\",\"前端_vue_共用_babel.md\":\"cf647abc\",\"前端_vue_共用_editorconfig.md\":\"c36308c4\",\"前端_vue_共用_keepalive.md\":\"deb68c8e\",\"前端_vue_共用_pinia.md\":\"80526775\",\"前端_vue_共用_sass.md\":\"855a3cf2\",\"前端_vue_共用_serviceenv环境搭建.md\":\"abbe0d31\",\"前端_vue_共用_slot.md\":\"d6b2125e\",\"前端_vue_共用_suspense.md\":\"8200392e\",\"前端_vue_共用_vue-router.md\":\"8e1bb84a\",\"前端_vue_共用_watch.md\":\"c46479ce\",\"前端_vue_共用_指令.md\":\"1d82c421\",\"前端_开发规范_开发项目注意事项.md\":\"ff4e27c0\",\"前端_样式布局_css3.md\":\"f14b0d1b\",\"前端_样式布局_css.md\":\"c408f1c8\",\"前端_样式布局_elementui_lecture.md\":\"119705ff\",\"前端_样式布局_less.md\":\"c1c14661\",\"前端_样式布局_naive_lecture.md\":\"5d813048\",\"前端_样式布局_elementplus.md\":\"369bf784\",\"前端_样式布局_flex.md\":\"043555ed\",\"前端_样式布局_自定义变量.md\":\"3f8ebc18\",\"后端_node_lecture.md\":\"4380cdc6\",\"后端_java_lecture.md\":\"4168049d\",\"建模_revit2019_lecture.md\":\"71672b31\",\"数学_地学建模_地学建模.md\":\"b22a1f9e\",\"数学_线代_lecture.md\":\"04d62c47\",\"数学_高数_lecture.md\":\"388147a3\",\"数据库_postgre.md\":\"396f2567\",\"数据库_redis_lecture.md\":\"85dd5de1\",\"服务器_webgis服务.md\":\"09ae4230\",\"服务器_geoserver.md\":\"c459542a\",\"服务器_gitee.md\":\"11eece10\",\"服务器_linux.md\":\"da742963\",\"服务器_腾讯云.md\":\"b181a3a8\",\"服务器_阿里云.md\":\"a215e95a\",\"算法_lecture.md\":\"71411712\",\"英语_lecture.md\":\"4d677bbf\",\"软件_coreldraw.md\":\"93b13f36\",\"软件_webstorm.md\":\"de1fd8f3\",\"软件_arcgispro.md\":\"d46f2c41\",\"软件_arcmap.md\":\"aebe8900\",\"软件_catalogue.md\":\"d61f8e0a\",\"面试题_2022_lecture.md\":\"fd2a7853\",\"面试题_2023_20230101.md\":\"7d110eea\",\"面试题_2023_20230116.md\":\"5ba7fa6f\",\"面试题_2023_20230201.md\":\"28a77b39\"}")</script>
    <script type="module" async src="/assets/app.08aaf608.js"></script>
    
  </body>
</html>